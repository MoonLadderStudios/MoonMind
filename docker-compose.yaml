services:
  keycloak-db:
    profiles: ["keycloak"]
    image: postgres:${POSTGRES_VERSION:-17}
    environment:
      POSTGRES_USER: keycloak
      POSTGRES_PASSWORD: ${KC_DB_PW:-keycloak}
      POSTGRES_DB: keycloak
    volumes: [ keycloak-data:/var/lib/postgresql/data ]
    networks: [ local-network ]
    restart: unless-stopped

  keycloak:
    profiles: ["keycloak"]
    image: quay.io/keycloak/keycloak:24.0
    command: >
      start-dev
      --proxy-headers=xforwarded
      --hostname-url=http://keycloak:8080
      --import-realm
      --db=postgres
      --db-url=jdbc:postgresql://keycloak-db:5432/keycloak
      --db-username=keycloak
      --db-password=${KC_DB_PW:-keycloak}
    environment:
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: ${KC_ADMIN_PW:-admin}
    volumes:
      - ./keycloak/realm-export.json:/opt/keycloak/data/import/realm-export.json:ro
    ports: [ "8085:8080" ]        # hostâ†’container
    depends_on:
      - keycloak-db
    networks: [ local-network ]
    restart: unless-stopped

  ui:
    image: ghcr.io/open-webui/open-webui:main
    volumes:
      - open-webui:/app/backend/data
    ports:
      - 8080:8080
    environment:
      - OPENAI_API_BASE_URL=${OPENAI_API_BASE_URL:-http://api:5000/v1}
      - WEBUI_AUTH=${WEBUI_AUTH:-false}
      # - WEBUI_FORWARD_AUTH_HEADER=${WEBUI_FORWARD_AUTH_HEADER:-true} # Keep or remove based on final setup with OIDC
      - ENABLE_OLLAMA_API=false
      # OIDC specific variables for OpenWebUI
      - ENABLE_OAUTH_SIGNUP=${WEBUI_AUTH:-false}
      - OAUTH_PROVIDER_NAME=Keycloak # Can be changed by .env if needed
      - OAUTH_CLIENT_ID=open-webui # As defined in realm-export.json
      - OAUTH_CLIENT_SECRET= # Left blank for PKCE
      - OAUTH_SCOPES=openid email profile
      - OPENID_PROVIDER_URL=http://keycloak:8080/realms/moonmind/.well-known/openid-configuration # Internal URL for Keycloak
      - WEBUI_FORWARD_AUTH_HEADER=${WEBUI_AUTH:-false} # Important for API to get the token
    env_file:
      - .env
    restart: unless-stopped
    networks:
      - local-network
    depends_on:
      - api

  api:
    build:
      context: .
      dockerfile: ./api_service/Dockerfile
    image: ghcr.io/moonladderstudios/moonmind:latest
    ports:
      - "5000:5000"
    environment:
      - PYTHONPATH=/app
      - LOG_LEVEL=${LOG_LEVEL:-DEBUG}
      - PYTHONUNBUFFERED=1
      - FASTAPI_RELOAD=${FASTAPI_RELOAD:-false}
      - MODEL_CONTEXT_PROTOCOL_ENABLED=true
      - MODEL_CONTEXT_PROTOCOL_PORT=5000
      - MODEL_CONTEXT_PROTOCOL_HOST=0.0.0.0
      - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
      # OIDC specific variables for API service
      - AUTH_PROVIDER=${AUTH_PROVIDER:-disabled} # local, google, or disabled
      - OIDC_ISSUER_URL=${OIDC_ISSUER_URL:-http://keycloak:8080/realms/moonmind} # For 'local'
      - OIDC_CLIENT_ID=${OIDC_CLIENT_ID:-api-service} # For 'local', matches realm-export.json
      - OIDC_CLIENT_SECRET=${API_CLIENT_SECRET:-changeme} # For 'local', matches realm-export.json
      - JWT_SECRET=${JWT_SECRET:-devsecret} # For 'disabled' auth provider (legacy JWT)
    env_file:
      - .env
    volumes:
      - ./model_data:/app/model_data
      - ./api_service:/app/api_service
      - ./moonmind:/app/moonmind:ro
      - ./keycloak:/app/keycloak:ro # Mount keycloak configs if needed by api, or remove if only for keycloak service
    command: sh /app/api_service/entrypoint.sh
    networks:
      - local-network
    labels:
      - "ai.model.context.protocol.version=0.1"
      - "ai.model.context.protocol.endpoint=/context"
    depends_on:
      init-db:
        condition: service_completed_successfully
      api-db:
        condition: service_started

  api-db:
    image: postgres:${POSTGRES_VERSION:-17}
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-password}
      POSTGRES_DB: ${POSTGRES_DB:-moonmind}
    volumes:
      - api-db-data:/var/lib/postgresql/data
    expose:
      - "5432"
    networks:
      - local-network
    restart: unless-stopped

  qdrant:
    image: qdrant/qdrant:v1.14.1
    ports:
      - "6333:6333"
      - "6334:6334"
    volumes:
      - qdrant-storage:/qdrant/storage
    networks:
      - local-network

  init-db:
    build:
      context: .
      dockerfile: ./api_service/Dockerfile
    image: ghcr.io/moonladderstudios/moonmind:latest
    environment:
      - DATABASE_URL=postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD:-password}@api-db:5432/${POSTGRES_DB:-moonmind}
      - PYTHONPATH=/app
      - LOG_LEVEL=INFO
      - PYTHONUNBUFFERED=1
      - QDRANT_URL=${QDRANT_URL:-http://qdrant:6333}
    env_file:
      - .env
    volumes:
      - ./moonmind:/app/moonmind:ro
      - ./tools:/app/tools:ro
      - ./model_data:/app/model_data:ro
      - ./api_service:/app/api_service:ro
      - ./init_db:/app/init_db
    command: sh /app/init_db/init_db_entrypoint.sh
    networks:
      - local-network
    restart: "no"
    depends_on:
      - api-db
      - qdrant

  ollama:
    profiles: ["ollama"]
    image: ollama/ollama:latest
    ports:
      - 11434:11434
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./model_data:/root/.ollama/models
      - ./tools/entrypoint-ollama.sh:/entrypoint-ollama.sh:ro
    entrypoint: ["/bin/sh", "/entrypoint-ollama.sh"]
    networks:
      - local-network
    env_file:
      - .env
    environment:
      - OLLAMA_CONTEXT_LENGTH=32768
      - OLLAMA_FLASH_ATTENTION=true
      - OLLAMA_KV_CACHE_TYPE=q4_0

  openhands:
    profiles: ["openhands"]
    image: docker.all-hands.dev/all-hands-ai/openhands:0.39
    container_name: openhands-app
    pull_policy: always
    tty: true
    stdin_open: true
    ports:
      - "3000:3000"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./.openhands-state-data:/.openhands-state
      - ./config.toml:/app/openhands/config.toml:ro
      - .:/workspace
    environment:
      - SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.39-nikolaik
      - LOG_ALL_EVENTS=true
    extra_hosts:
      - host.docker.internal:host-gateway
    networks:
      - local-network
    env_file:
      - .env

  vllm:
    profiles: ["vllm"]
    image: vllm/vllm-openai:latest
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./model_data:/root/.cache/huggingface/hub
      - ./tools/entrypoint-vllm.sh:/entrypoint-vllm.sh:ro
    ports:
      - "8000:8000"
    environment:
      - MODEL_NAME=${VLLM_MODEL_NAME:-ByteDance-Seed/UI-TARS-1.5-7B}
      - DTYPE=${VLLM_DTYPE:-float16}
      - GPU_MEMORY_UTILIZATION=${VLLM_GPU_MEMORY_UTILIZATION:-0.95}
      - HF_HOME=/root/.cache/huggingface
      - MAX_MODEL_LEN=${VLLM_MAX_MODEL_LEN:-32768}
      - NVIDIA_DRIVER_CAPABILITIES=all
    entrypoint: ["/bin/sh", "/entrypoint-vllm.sh"]
    networks:
      - local-network
    tty: true
    init: true

volumes:
  open-webui:
  qdrant-storage:
  api-db-data:
  keycloak-data:

networks:
  local-network:
    external: true
