version: '3.8'

services:
  ui:
    image: ghcr.io/open-webui/open-webui:main
    volumes:
      - open-webui:/app/backend/data
    ports:
      - 8080:8080
    environment:
      - OPENAI_API_BASE_URL=http://rag:8000/v1
      # - OPENAI_API_KEY=dummy-key
    env_file:
      - .env
    restart: unless-stopped
    networks:
      - local-network

  rag:
    build:
      context: .
      dockerfile: ./rag/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - LOG_LEVEL=DEBUG
      - PYTHONUNBUFFERED=1
      - FASTAPI_RELOAD=${FASTAPI_RELOAD:-0}
    env_file:
      - .env
    volumes:
      - ./models:/app/models:ro
      - ./rag/app/main.py:/app/main.py:ro
      - ./rag/app/routers:/app/routers:ro
      - ./moonai:/app/moonai:ro
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    shm_size: "2g"
    ipc: host
    ulimits:
      memlock:
        soft: -1
        hard: -1
      stack: 67108864
    command: >
      sh -c "
      if [ \"$FASTAPI_RELOAD\" = \"True\" ]; then
        uvicorn main:app --host 0.0.0.0 --port 8000 --reload;
      else
        uvicorn main:app --host 0.0.0.0 --port 8000;
      fi"
    networks:
      - local-network

volumes:
  open-webui:

networks:
  local-network:
    external: true
